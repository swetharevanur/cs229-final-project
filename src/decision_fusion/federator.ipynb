{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the following ordering of classes:\n",
    "\n",
    "`damaged_infrastructure`: 0, `damaged_nature`: 1, `fires`: 2, `flood`: 3, `human_damage`: 4, `non_damage`: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.data import Field, TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_root = '../../data/img_data'\n",
    "text_root = '../../data/text_data'\n",
    "BASE_PATH = '../baselines'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Joint Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_train_data_fname = '../../intermediates/cleaned_text_train.pkl'\n",
    "all_val_data_fname = '../../intermediates/cleaned_text_val.pkl'\n",
    "all_test_data_fname = '../../intermediates/cleaned_text_test.pkl'\n",
    "\n",
    "all_train_data = pickle.load(open(all_train_data_fname, 'rb'))\n",
    "all_val_data = pickle.load(open(all_val_data_fname, 'rb'))\n",
    "all_test_data = pickle.load(open(all_test_data_fname, 'rb'))\n",
    "\n",
    "split_data = {\n",
    "    'train': all_train_data,\n",
    "    'val': all_val_data,\n",
    "    'test': all_test_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_captions = {}\n",
    "for split in split_data: \n",
    "    keys = list(split_data[split]['file_name'].values)\n",
    "    values = list(split_data[split]['text'].values)\n",
    "    path_to_captions[split] = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultimodalFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, captions, transform = None):\n",
    "        super(MultimodalFolder, self).__init__(root, transform = transform)\n",
    "        self.imgs = self.samples\n",
    "        self.captions = captions\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label_dict = {'damaged_infrastructure': 0,\n",
    "                      'damaged_nature': 1,\n",
    "                      'fires': 2, \n",
    "                      'flood': 3,\n",
    "                      'human_damage': 4,\n",
    "                      'non_damage': 5}\n",
    "        \n",
    "        img, _ = super(MultimodalFolder, self).__getitem__(index)\n",
    "        \n",
    "        path, _ = self.imgs[index]\n",
    "        path = re.sub(r'[\\x80-\\xFF]', '' , path)\n",
    "        path, base_fname = path.rsplit('/', 1)\n",
    "        \n",
    "        label, split = path.rsplit('/')[-1], path.rsplit('/')[-2]\n",
    "        curr_fname = base_fname.rsplit('.')[0] + '.txt'\n",
    "        \n",
    "        sample = {'fname': base_fname, 'image': img, 'caption': self.captions[curr_fname]}\n",
    "        return sample, label_dict[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale = (0.9, 1.0)), \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(size = (224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size = (224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ResNet-50 Predictions for Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_pickle_files = {\n",
    "    'train':(os.path.join('decisions', 'img_train_pred.pkl'), \n",
    "            os.path.join('decisions', 'img_train_gt.pkl')), \n",
    "    'val':(os.path.join('decisions', 'img_val_pred.pkl'),\n",
    "          os.path.join('decisions', 'img_val_gt.pkl')),\n",
    "    'test':(os.path.join('decisions', 'img_test_pred.pkl'),\n",
    "           os.path.join('decisions', 'img_test_gt.pkl'))\n",
    "}\n",
    "\n",
    "def img_model_run_handler(model):\n",
    "    from PIL import ImageFile\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    \n",
    "    image_datasets = {x: MultimodalFolder(root = os.path.join(img_root, x), \n",
    "                                          captions = path_to_captions[x], transform = data_transforms[x]) \n",
    "                      for x in ['train', 'val', 'test']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size = 32, shuffle = False, num_workers = 0)\n",
    "                   for x in ['train', 'val', 'test']}\n",
    "\n",
    "    X_text_train, X_text_val, X_text_test = [], [], []\n",
    "    y_text_train, y_text_val, y_text_test = [], [], []\n",
    "    test_ordered_captions = {\n",
    "        'train': X_text_train,\n",
    "        'val': X_text_val,\n",
    "        'test': X_text_test\n",
    "    }\n",
    "    test_ordered_labels = {\n",
    "        'train': y_text_train,\n",
    "        'val': y_text_val,\n",
    "        'test': y_text_test\n",
    "    }\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            preds_list, gt_list = [], []\n",
    "            for samples, labels in dataloaders[split]:\n",
    "#                 print(samples)\n",
    "#                 print(samples['fname'])\n",
    "#                 print(samples['caption'])\n",
    "#                 return\n",
    "#                 images = samples['image']                \n",
    "#                 images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "#                 outputs = model(images)\n",
    "                \n",
    "#                 preds_list.extend(list(np.asarray(torch.max(outputs, 1)[1])))\n",
    "#                 gt_list.extend(list(np.asarray(labels)))\n",
    "                test_ordered_captions[split].extend(samples['caption'])\n",
    "                test_ordered_labels[split].extend(list(np.asarray(labels)))\n",
    "\n",
    "#             pickle_fns = img_pickle_files[split]\n",
    "#             with open(pickle_fns[0], 'wb') as handle:\n",
    "#                 pickle.dump(preds_list, handle)\n",
    "#             with open(pickle_fns[1], 'wb') as handle:\n",
    "#                 pickle.dump(gt_list, handle)\n",
    "                \n",
    "    return test_ordered_captions, test_ordered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f83394f6aabe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresnet_state_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img_only'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trained_models'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet50_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_state_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_ordered_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ordered_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_model_run_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-15ddca1e8130>\u001b[0m in \u001b[0;36mimg_model_run_handler\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#                 preds_list.extend(list(np.asarray(torch.max(outputs, 1)[1])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#                 gt_list.extend(list(np.asarray(labels)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mtest_ordered_captions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mtest_ordered_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "resnet_model = torchvision.models.resnet50(pretrained = False)\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, 6)\n",
    "\n",
    "resnet_state_file = os.path.join(BASE_PATH, 'img_only', 'output', 'trained_models', 'resnet50_model')\n",
    "resnet_model.load_state_dict(torch.load(resnet_state_file))\n",
    "test_ordered_captions, test_ordered_labels = img_model_run_handler(resnet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_total = test_ordered_captions['train'] + test_ordered_captions['val'] + test_ordered_captions['test']\n",
    "y_total = test_ordered_labels['train'] + test_ordered_labels['val'] + test_ordered_labels['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'of', 'the', 'houses', 'affected', 'by', 'the', 'blast', 'odorna', 'accrafloods', 'fire', 'blast', 'lives', 'photography']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-724f8215fba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# split up caption into lists\n",
    "for i in range(len(X_total)):\n",
    "    X_total[i] = X_total[i][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5831\n",
      "5831\n"
     ]
    }
   ],
   "source": [
    "print(len(X_total))\n",
    "print(len(y_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(X_total, size = 100, window = 5, min_count = 5, workers = 2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.vectors)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer = lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-ef6e0d4093be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'precision_macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall_macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m svm_model = cross_validate(svm_tfidf, X_total, y_total, cv = 20, scoring = scoring, \n\u001b[0;32m----> 3\u001b[0;31m                            return_train_score = True, return_estimator = True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scoring = ['precision_macro', 'recall_macro', 'accuracy']\n",
    "svm_model = cross_validate(svm_tfidf, X_total, y_total, cv = 20, scoring = scoring, \n",
    "                           return_train_score = True, return_estimator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': (Pipeline(memory=None,\n",
       "       steps=[('tfidf_vectorizer', TfidfVectorizer(analyzer=<function <lambda> at 0x115608268>, binary=False,\n",
       "          decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "          encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "          max_features=None, min_df=1, ngram_range=(1, 1), norm='l...r', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))]), Pipeline(memory=None,\n",
       "       steps=[('tfidf_vectorizer', TfidfVectorizer(analyzer=<function <lambda> at 0x115608268>, binary=False,\n",
       "          decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "          encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "          max_features=None, min_df=1, ngram_range=(1, 1), norm='l...r', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))]), Pipeline(memory=None,\n",
       "       steps=[('tfidf_vectorizer', TfidfVectorizer(analyzer=<function <lambda> at 0x115608268>, binary=False,\n",
       "          decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "          encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "          max_features=None, min_df=1, ngram_range=(1, 1), norm='l...r', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))]), Pipeline(memory=None,\n",
       "       steps=[('tfidf_vectorizer', TfidfVectorizer(analyzer=<function <lambda> at 0x115608268>, binary=False,\n",
       "          decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "          encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "          max_features=None, min_df=1, ngram_range=(1, 1), norm='l...r', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))]), Pipeline(memory=None,\n",
       "       steps=[('tfidf_vectorizer', TfidfVectorizer(analyzer=<function <lambda> at 0x115608268>, binary=False,\n",
       "          decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "          encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "          max_features=None, min_df=1, ngram_range=(1, 1), norm='l...r', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))])),\n",
       " 'fit_time': array([6.32251787, 7.07843399, 6.27367806, 6.13554192, 6.51348114]),\n",
       " 'score_time': array([2.71943712, 2.61207008, 2.11140704, 2.37073112, 2.49885893]),\n",
       " 'test_accuracy': array([0.88869863, 0.88346187, 0.87221269, 0.90308748, 0.90034364]),\n",
       " 'test_precision_macro': array([0.89701457, 0.84065756, 0.88326654, 0.88363778, 0.90408082]),\n",
       " 'test_recall_macro': array([0.79808332, 0.84917821, 0.71137022, 0.81409946, 0.8016407 ]),\n",
       " 'train_accuracy': array([0.98820502, 0.9897084 , 0.98585209, 0.98949625, 0.98778659]),\n",
       " 'train_precision_macro': array([0.98493419, 0.98565085, 0.9812513 , 0.9855205 , 0.98344065]),\n",
       " 'train_recall_macro': array([0.97614072, 0.97771432, 0.97022085, 0.9785093 , 0.974375  ])}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_estimator = svm_model['estimator'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train_preds = svm_estimator.predict(test_ordered_captions['train'])\n",
    "text_val_preds = svm_estimator.predict(test_ordered_captions['val'])\n",
    "text_test_preds = svm_estimator.predict(test_ordered_captions['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499\n",
      "1166\n",
      "1166\n"
     ]
    }
   ],
   "source": [
    "y_preds = svm_estimator.predict(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682730234951124"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_total, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sz = len(test_ordered_labels['train'])\n",
    "val_sz = len(test_ordered_labels['val'])\n",
    "test_sz = len(test_ordered_labels['test'])\n",
    "\n",
    "text_train_preds = y_preds[:train_sz]\n",
    "print(len(text_train_preds))\n",
    "text_val_preds = y_preds[train_sz : train_sz + val_sz]\n",
    "print(len(text_val_preds))\n",
    "text_test_preds = y_preds[train_sz + val_sz: train_sz + val_sz + test_sz]\n",
    "print(len(text_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9539868533866819\n",
      "0.9905660377358491\n",
      "0.9888507718696398\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.accuracy_score(test_ordered_labels['train'], text_train_preds))\n",
    "print(sklearn.metrics.accuracy_score(test_ordered_labels['val'], text_val_preds))\n",
    "print(sklearn.metrics.accuracy_score(test_ordered_labels['test'], text_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate Labels for Federator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train_correct = list((np.array(text_train_preds) == test_ordered_labels['train']) * 1)\n",
    "text_val_correct = list((np.array(text_val_preds) == test_ordered_labels['val']) * 1)\n",
    "text_test_correct = list((np.array(text_test_preds) == test_ordered_labels['test']) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682730234951124"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(text_train_correct) + sum(text_val_correct) + sum(text_test_correct))/(len(text_train_correct) + len(text_val_correct) + len(text_test_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_train_preds = pickle.load(open(img_pickle_files['train'][0], 'rb'))\n",
    "img_val_preds = pickle.load(open(img_pickle_files['val'][0], 'rb'))\n",
    "img_test_preds = pickle.load(open(img_pickle_files['test'][0], 'rb'))\n",
    "\n",
    "img_train_correct = list((np.array(img_train_preds) == test_ordered_labels['train']) * 1)\n",
    "img_val_correct = list((np.array(img_val_preds) == test_ordered_labels['val']) * 1)\n",
    "img_test_correct = list((np.array(img_test_preds) == test_ordered_labels['test']) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multimodal_labels = {\n",
    "    'train': [text_train_correct, img_train_correct],\n",
    "    'val': [text_val_correct, img_val_correct],\n",
    "    'test': [text_test_correct, img_test_correct]\n",
    "}\n",
    "\n",
    "# 1 if img = 1 but text = 0, else 0\n",
    "federator_train = list((np.array(img_train_correct) > np.array(text_train_correct)) * 1)\n",
    "federator_val = list((np.array(img_val_correct) > np.array(text_val_correct)) * 1)\n",
    "federator_test = list((np.array(img_test_correct) > np.array(text_test_correct)) * 1)\n",
    "federator_total = federator_train + federator_val + federator_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and Train Federator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swetharevanur/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "fed_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer = lambda x: x)), \\\n",
    "                      (\"linear svc\", SVC(kernel = \"linear\"))])\n",
    "federator = cross_validate(fed_tfidf, X_total[:train_sz + val_sz], federator_total[:train_sz + val_sz], cv = 5, scoring = scoring, \n",
    "                           return_train_score = True, return_estimator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166\n",
      "1166\n"
     ]
    }
   ],
   "source": [
    "federator_estimator = federator['estimator'][0]\n",
    "federator_total_preds = federator_estimator.predict(X_total[train_sz + val_sz:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.99228\n",
      "Test F1 Score: 0.98844\n",
      "Test Precision: 0.98462\n",
      "Test Recall: 0.99228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swetharevanur/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/swetharevanur/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %.5f' % sklearn.metrics.accuracy_score(federator_total[train_sz + val_sz:], federator_total_preds))\n",
    "print('Test F1 Score: %.5f' % sklearn.metrics.f1_score(federator_total[train_sz + val_sz:], federator_total_preds, average = 'weighted'))\n",
    "print('Test Precision: %.5f' % sklearn.metrics.precision_score(federator_total[train_sz + val_sz:], federator_total_preds, average = 'weighted'))\n",
    "print('Test Recall: %.5f' % sklearn.metrics.recall_score(federator_total[train_sz + val_sz:], federator_total_preds, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5 fold cross val\n",
    "Test Accuracy: 0.92814\n",
    "Test F1 Score: 0.92878\n",
    "Test Precision: 0.93481\n",
    "Test Recall: 0.92814\n",
    "\n",
    "#### 10 fold cross val\n",
    "Test Accuracy: 0.93020\n",
    "Test F1 Score: 0.93086\n",
    "Test Precision: 0.93815\n",
    "Test Recall: 0.93020\n",
    "\n",
    "#### 20 fold cross val\n",
    "Test Accuracy: 0.94478\n",
    "Test F1 Score: 0.94523\n",
    "Test Precision: 0.95016\n",
    "Test Recall: 0.94478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Downstream Classifier Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_total_preds = list(text_train_preds) + list(text_val_preds) + list(text_test_preds)\n",
    "img_total_preds = img_train_preds + img_val_preds + img_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "federator_classifications = []\n",
    "\n",
    "for i in range(len(y_total[train_sz + val_sz:])):\n",
    "    if federator_total_preds[i] == 1:\n",
    "        federator_classifications.append(img_test_preds[i])\n",
    "    else:\n",
    "        federator_classifications.append(list(text_test_preds)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1166"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(federator_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.98885\n",
      "Test F1 Score: 0.98883\n",
      "Test Precision: 0.98899\n",
      "Test Recall: 0.98885\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %.5f' % sklearn.metrics.accuracy_score(y_total[train_sz + val_sz:], federator_classifications))\n",
    "print('Test F1 Score: %.5f' % sklearn.metrics.f1_score(y_total[train_sz + val_sz:], federator_classifications, average = 'weighted'))\n",
    "print('Test Precision: %.5f' % sklearn.metrics.precision_score(y_total[train_sz + val_sz:], federator_classifications, average = 'weighted'))\n",
    "print('Test Recall: %.5f' % sklearn.metrics.recall_score(y_total[train_sz + val_sz:], federator_classifications, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_total[train_sz + val_sz:], federator_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.98954704 0.         0.         0.00696864 0.         0.00348432]\n",
      " [0.0212766  0.96808511 0.         0.         0.         0.0106383 ]\n",
      " [0.01515152 0.         0.98484848 0.         0.         0.        ]\n",
      " [0.03658537 0.         0.         0.96341463 0.         0.        ]\n",
      " [0.06       0.         0.         0.         0.94       0.        ]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize = False, title='Feature Fusion Confusion Matrix', cmap = 'BuPu'):\n",
    "    if normalize: \n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "plt.close()\n",
    "plot_confusion_matrix(cm, classes = range(6), normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm federator_matrix.png\n",
    "plt.savefig('federator_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt = pickle.load(open('gt_list.pkl', 'rb'))\n",
    "pred = pickle.load(open('preds_list.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.87455197 0.05376344 0.01075269 0.00716846 0.00716846 0.04659498]\n",
      " [0.11206897 0.81896552 0.01724138 0.00862069 0.00862069 0.03448276]\n",
      " [0.07692308 0.06153846 0.84615385 0.         0.         0.01538462]\n",
      " [0.06060606 0.03030303 0.01515152 0.83333333 0.         0.06060606]\n",
      " [0.11320755 0.         0.03773585 0.         0.81132075 0.03773585]\n",
      " [0.00681431 0.0153322  0.00170358 0.00170358 0.         0.97444634]]\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cm = sklearn.metrics.confusion_matrix(gt, pred)\n",
    "plt.close()\n",
    "plot_confusion_matrix(cm, classes = range(6), normalize = True)\n",
    "plt.savefig('fusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
